From 708de8da6c1100d333ba38849095baccea89dbd7 Mon Sep 17 00:00:00 2001
From: X512 <danger_mail@list.ru>
Date: Mon, 26 Jul 2021 02:57:36 +0900
Subject: kernel/arch/vm: implement for riscv64 (2)

Change-Id: I3189d21d775f7ff34d5bbe5cf8490269a22e373a
---
 .../arch/riscv64/arch_vm_translation_map.h    |  25 +-
 .../arch/riscv64/RISCV64VMTranslationMap.cpp  | 144 ++++++------
 .../arch/riscv64/RISCV64VMTranslationMap.h    |   3 +
 src/system/kernel/arch/riscv64/arch_vm.cpp    | 196 +++++++++++++++-
 .../arch/riscv64/arch_vm_translation_map.cpp  | 215 +++---------------
 5 files changed, 320 insertions(+), 263 deletions(-)

diff --git a/headers/private/kernel/arch/riscv64/arch_vm_translation_map.h b/headers/private/kernel/arch/riscv64/arch_vm_translation_map.h
index 853d7202c0..5f09fc5c01 100644
--- a/headers/private/kernel/arch/riscv64/arch_vm_translation_map.h
+++ b/headers/private/kernel/arch/riscv64/arch_vm_translation_map.h
@@ -7,20 +7,23 @@
 
 #include <arch/vm_translation_map.h>
 
-#ifdef __cplusplus
-extern "C" {
-#endif
 
-void riscv64_translation_map_change_asid(VMTranslationMap *map);
+//gVirtFromPhysOffset = virtAdr - physAdr;
+extern ssize_t gVirtFromPhysOffset;
 
-status_t riscv64_map_address_range(addr_t virtualAddress,
-	phys_addr_t physicalAddress, size_t size);
-void riscv64_unmap_address_range(addr_t virtualAddress, size_t size);
-status_t riscv64_remap_address_range(addr_t *virtualAddress, size_t size,
-	bool unmap);
 
-#ifdef __cplusplus
+static inline void*
+VirtFromPhys(phys_addr_t physAdr)
+{
+	return (void*)(physAdr + gVirtFromPhysOffset);
 }
-#endif
+
+
+static inline phys_addr_t
+PhysFromVirt(void* virtAdr)
+{
+	return (phys_addr_t)virtAdr - gVirtFromPhysOffset;
+}
+
 
 #endif /* _KERNEL_ARCH_RISCV64_VM_TRANSLATION_MAP_H */
diff --git a/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.cpp b/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.cpp
index 7234beb16d..3ea75bdb00 100644
--- a/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.cpp
+++ b/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.cpp
@@ -10,6 +10,8 @@
 #include <util/AutoLock.h>
 
 
+//#define DISABLE_MODIFIED_FLAGS 1
+
 //#define DO_TRACE
 #ifdef DO_TRACE
 #	define TRACE(x...) dprintf(x)
@@ -21,54 +23,18 @@
 	panic("not implemented: %s\n", __PRETTY_FUNCTION__)
 
 
-static inline void*
-VirtFromPhys(uint64_t physAdr)
-{
-	return (void*)(physAdr + (KERNEL_PMAP_BASE - 0x80000000));
-}
-
-
-static inline uint64_t
-PhysFromVirt(void *virtAdr)
-{
-	return (uint64)virtAdr - (KERNEL_PMAP_BASE - 0x80000000);
-}
-
-
-static void
-WriteVmPage(vm_page* page)
-{
-	dprintf("0x%08" B_PRIxADDR " ", page->physical_page_number * B_PAGE_SIZE);
-	switch (page->State()) {
-		case PAGE_STATE_ACTIVE:   dprintf("A"); break;
-		case PAGE_STATE_INACTIVE: dprintf("I"); break;
-		case PAGE_STATE_MODIFIED: dprintf("M"); break;
-		case PAGE_STATE_CACHED:   dprintf("C"); break;
-		case PAGE_STATE_FREE:     dprintf("F"); break;
-		case PAGE_STATE_CLEAR:    dprintf("L"); break;
-		case PAGE_STATE_WIRED:    dprintf("W"); break;
-		case PAGE_STATE_UNUSED:   dprintf("-"); break;
-	}
-	dprintf(" ");
-	if (page->busy)         dprintf("B"); else dprintf("-");
-	if (page->busy_writing) dprintf("W"); else dprintf("-");
-	if (page->accessed)     dprintf("A"); else dprintf("-");
-	if (page->modified)     dprintf("M"); else dprintf("-");
-	if (page->unused)       dprintf("U"); else dprintf("-");
-
-	dprintf(" usage:%3u", page->usage_count);
-	dprintf(" wired:%5u", page->WiredCount());
-}
-
-
 static void
 FreePageTable(page_num_t ppn, bool isKernel, uint32 level = 2)
 {
 	if (level > 0) {
 		Pte* pte = (Pte*)VirtFromPhys(ppn * B_PAGE_SIZE);
-		// NOTE: adjust range if changing kernel address space range
-		for (uint32 i = (level == 2 && !isKernel) ? 256 : 0; i < pteCount;
-			i++) {
+		uint64 beg = 0;
+		uint64 end = pteCount - 1;
+		if (level == 2 && !isKernel) {
+			beg = VirtAdrPte(USER_BASE, 2);
+			end = VirtAdrPte(USER_TOP, 2);
+		}
+		for (uint64 i = beg; i <= end; i++) {
 			if ((1 << pteValid) & pte[i].flags)
 				FreePageTable(pte[i].ppn, isKernel, level - 1);
 		}
@@ -89,8 +55,13 @@ GetPageTableSize(page_num_t ppn, bool isKernel, uint32 level = 2)
 
 	uint64 size = 1;
 	Pte* pte = (Pte*)VirtFromPhys(ppn * B_PAGE_SIZE);
-	// NOTE: adjust range if changing kernel address space range
-	for (uint32 i = (level == 2 && !isKernel) ? 256 : 0; i < pteCount; i++) {
+	uint64 beg = 0;
+	uint64 end = pteCount - 1;
+	if (level == 2 && !isKernel) {
+		beg = VirtAdrPte(USER_BASE, 2);
+		end = VirtAdrPte(USER_TOP, 2);
+	}
+	for (uint64 i = beg; i <= end; i++) {
 		if ((1 << pteValid) & pte[i].flags)
 			size += GetPageTableSize(pte[i].ppn, isKernel, level - 1);
 	}
@@ -120,8 +91,8 @@ RISCV64VMTranslationMap::LookupPte(addr_t virtAdr, bool alloc,
 				VMAddressSpace::Kernel()->TranslationMap();
 			Pte *kernelPageTable = (Pte*)VirtFromPhys(kernelMap->PageTable());
 			Pte *userPageTable = (Pte*)VirtFromPhys(fPageTable);
-			// NOTE: adjust range if changing kernel address space range
-			for (int i = 0; i < 256; i++) {
+			for (uint64 i = VirtAdrPte(KERNEL_BASE, 2);
+				i <= VirtAdrPte(KERNEL_TOP, 2); i++) {
 				Pte *pte = &userPageTable[i];
 				pte->ppn = kernelPageTable[i].ppn;
 				pte->flags |= (1 << pteValid);
@@ -129,8 +100,8 @@ RISCV64VMTranslationMap::LookupPte(addr_t virtAdr, bool alloc,
 		}
 	}
 	Pte *pte = (Pte*)VirtFromPhys(fPageTable);
-	for (int level = 2; level > 0; level --) {
-		pte += PhysAdrPte(virtAdr, level);
+	for (int level = 2; level > 0; level--) {
+		pte += VirtAdrPte(virtAdr, level);
 		if (!((1 << pteValid) & pte->flags)) {
 			if (!alloc)
 				return NULL;
@@ -144,7 +115,7 @@ RISCV64VMTranslationMap::LookupPte(addr_t virtAdr, bool alloc,
 		}
 		pte = (Pte*)VirtFromPhys(B_PAGE_SIZE * pte->ppn);
 	}
-	pte += PhysAdrPte(virtAdr, 0);
+	pte += VirtAdrPte(virtAdr, 0);
 	return pte;
 }
 
@@ -179,13 +150,11 @@ RISCV64VMTranslationMap::~RISCV64VMTranslationMap()
 	TRACE("  pageTableSize: %" B_PRIu64 "\n", fPageTableSize);
 	TRACE("  GetPageTableSize(): %" B_PRIu64 "\n",
 		GetPageTableSize(fPageTable / B_PAGE_SIZE, fIsKernel));
-	if (!fIsKernel) {
-		// We are going to delete currently used page table, switch to
-		// kernel page table.
-		RISCV64VMTranslationMap* kernelMap = (RISCV64VMTranslationMap*)
-			VMAddressSpace::Kernel()->TranslationMap();
-		SetSatp(kernelMap->Satp());
-	}
+
+	ASSERT_ALWAYS(!fIsKernel);
+	// Can't delete currently used page table
+	ASSERT_ALWAYS(::Satp() != Satp());
+
 	FreePageTable(fPageTable / B_PAGE_SIZE, fIsKernel);
 }
 
@@ -270,7 +239,11 @@ RISCV64VMTranslationMap::Map(addr_t virtualAddress,
 		if ((attributes & B_KERNEL_EXECUTE_AREA) != 0)
 			pte->flags |= (1 << pteExec);
 	}
-	pte->flags |= (1 << pteValid);
+	pte->flags |= (1 << pteValid)
+#ifdef DISABLE_MODIFIED_FLAGS
+		| (1 << pteAccessed) | (1 << pteDirty)
+#endif
+	;
 
 	FlushTlbPage(virtualAddress);
 
@@ -370,8 +343,9 @@ RISCV64VMTranslationMap::UnmapArea(VMArea* area, bool deletingAddressSpace,
 	bool ignoreTopCachePageFlags)
 {
 	TRACE("RISCV64VMTranslationMap::UnmapArea(0x%" B_PRIxADDR "(%s), 0x%"
-		B_PRIxADDR ", 0x%" B_PRIxSIZE ", %d)\n", (addr_t)area, area->name, base,
-		size, updatePageQueue);
+		B_PRIxADDR ", 0x%" B_PRIxSIZE ", %d, %d)\n", (addr_t)area, area->name,
+		area->Base(), area->Size(), deletingAddressSpace,
+		ignoreTopCachePageFlags);
 
 	if (area->cache_type == CACHE_TYPE_DEVICE || area->wiring != B_NO_LOCK) {
 		UnmapPages(area, area->Base(), area->Size(), true);
@@ -474,9 +448,10 @@ RISCV64VMTranslationMap::Query(addr_t virtualAddress,
 	*_physicalAddress = pte->ppn * B_PAGE_SIZE;
 
 	if (((1 << pteValid)    & pte->flags) != 0) *_flags |= PAGE_PRESENT;
+#ifndef DISABLE_MODIFIED_FLAGS
 	if (((1 << pteDirty)    & pte->flags) != 0) *_flags |= PAGE_MODIFIED;
 	if (((1 << pteAccessed) & pte->flags) != 0) *_flags |= PAGE_ACCESSED;
-
+#endif
 	if (((1 << pteUser) & pte->flags) != 0) {
 		if (((1 << pteRead)  & pte->flags) != 0) *_flags |= B_READ_AREA;
 		if (((1 << pteWrite) & pte->flags) != 0) *_flags |= B_WRITE_AREA;
@@ -520,7 +495,7 @@ status_t RISCV64VMTranslationMap::Protect(addr_t base, addr_t top,
 		}
 
 		Pte newPte = *pte;
-		newPte.flags = (1 << pteValid);
+		newPte.flags &= (1 << pteValid) | (1 << pteAccessed) | (1 << pteDirty);
 		if ((attributes & B_USER_PROTECTION) != 0) {
 			newPte.flags |= (1 << pteUser);
 			if ((attributes & B_READ_AREA)    != 0)
@@ -563,6 +538,30 @@ RISCV64VMTranslationMap::ProtectArea(VMArea* area, uint32 attributes)
 }
 
 
+static inline uint32
+ConvertAccessedFlags(uint32 flags)
+{
+	return
+		((flags & PAGE_MODIFIED) ? (1 << pteDirty   ) : 0) |
+		((flags & PAGE_ACCESSED) ? (1 << pteAccessed) : 0);
+}
+
+
+status_t
+RISCV64VMTranslationMap::SetFlags(addr_t address, uint32 flags)
+{
+	ThreadCPUPinner pinner(thread_get_current_thread());
+	Pte* pte = LookupPte(address, false, NULL);
+	if (pte == NULL || ((1 << pteValid) & pte->flags) == 0)
+		return B_OK;
+#ifndef DISABLE_MODIFIED_FLAGS
+	pte->flags |= ConvertAccessedFlags(flags);
+#endif
+	FlushTlbPage(address);
+	return B_OK;
+}
+
+
 status_t
 RISCV64VMTranslationMap::ClearFlags(addr_t address, uint32 flags)
 {
@@ -570,10 +569,9 @@ RISCV64VMTranslationMap::ClearFlags(addr_t address, uint32 flags)
 	Pte* pte = LookupPte(address, false, NULL);
 	if (pte == NULL || ((1 << pteValid) & pte->flags) == 0)
 		return B_OK;
-	pte->flags &= ~(
-		((flags & PAGE_MODIFIED) ? (1 << pteDirty   ) : 0) |
-		((flags & PAGE_ACCESSED) ? (1 << pteAccessed) : 0)
-	);
+#ifndef DISABLE_MODIFIED_FLAGS
+	pte->flags &= ~ConvertAccessedFlags(flags);
+#endif
 	FlushTlbPage(address);
 	return B_OK;
 }
@@ -595,6 +593,7 @@ RISCV64VMTranslationMap::ClearAccessedAndModified(VMArea* area, addr_t address,
 		return false;
 	}
 	Pte oldPte = *pte;
+#ifndef DISABLE_MODIFIED_FLAGS
 	if (unmapIfUnaccessed) {
 		if (((1 << pteAccessed) & pte->flags) != 0) {
 			pte->flags &= ~((1 << pteAccessed) | (1 << pteDirty));
@@ -605,6 +604,7 @@ RISCV64VMTranslationMap::ClearAccessedAndModified(VMArea* area, addr_t address,
 	} else {
 		pte->flags &= ~((1 << pteAccessed) | (1 << pteDirty));
 	}
+#endif
 	pinner.Unlock();
 	_modified = ((1 << pteDirty) & oldPte.flags) != 0;
 	if (((1 << pteAccessed) & oldPte.flags) != 0) {
@@ -688,7 +688,7 @@ RISCV64VMTranslationMap::MemcpyFromMap(char *to, addr_t from, size_t size)
 			TRACE("[!] not mapped: 0x%" B_PRIxADDR
 				", calling page fault handler\n", va0);
 			addr_t newIP;
-			vm_page_fault(va0, Ra(), true, false, true, &newIP);
+			vm_page_fault(va0, Ra(), true, false, true, true, &newIP);
 			pa0 = LookupAddr(va0);
 			TRACE("LookupAddr(0x%" B_PRIxADDR "): 0x%" B_PRIxADDR "\n",
 				va0, pa0);
@@ -723,7 +723,7 @@ RISCV64VMTranslationMap::MemsetToMap(addr_t to, char c, size_t count)
 			TRACE("[!] not mapped: 0x%" B_PRIxADDR
 				", calling page fault handler\n", va0);
 			addr_t newIP;
-			vm_page_fault(va0, Ra(), true, false, true, &newIP);
+			vm_page_fault(va0, Ra(), true, false, true, true, &newIP);
 			pa0 = LookupAddr(va0);
 			TRACE("LookupAddr(0x%" B_PRIxADDR "): 0x%" B_PRIxADDR "\n",
 				va0, pa0);
@@ -833,7 +833,9 @@ RISCV64VMPhysicalPageMapper::MemsetPhysical(phys_addr_t address, int value,
 {
 	TRACE("RISCV64VMPhysicalPageMapper::MemsetPhysical(0x%" B_PRIxADDR
 		", 0x%x, 0x%" B_PRIxADDR ")\n", address, value, length);
+	set_ac();
 	memset(VirtFromPhys(address), value, length);
+	clear_ac();
 	return B_OK;
 }
 
@@ -844,7 +846,9 @@ RISCV64VMPhysicalPageMapper::MemcpyFromPhysical(void* to, phys_addr_t from,
 {
 	TRACE("RISCV64VMPhysicalPageMapper::MemcpyFromPhysical(0x%" B_PRIxADDR
 		", 0x%" B_PRIxADDR ", %" B_PRIuSIZE ")\n", (addr_t)to, from, length);
+	set_ac();
 	memcpy(to, VirtFromPhys(from), length);
+	clear_ac();
 	return B_OK;
 }
 
@@ -855,7 +859,9 @@ RISCV64VMPhysicalPageMapper::MemcpyToPhysical(phys_addr_t to, const void* from,
 {
 	TRACE("RISCV64VMPhysicalPageMapper::MemcpyToPhysical(0x%" B_PRIxADDR
 		", 0x%" B_PRIxADDR ", %" B_PRIuSIZE ")\n", to, (addr_t)from, length);
+	set_ac();
 	memcpy(VirtFromPhys(to), from, length);
+	clear_ac();
 	return B_OK;
 }
 
@@ -866,5 +872,7 @@ RISCV64VMPhysicalPageMapper::MemcpyPhysicalPage(phys_addr_t to,
 {
 	TRACE("RISCV64VMPhysicalPageMapper::MemcpyPhysicalPage(0x%" B_PRIxADDR
 		", 0x%" B_PRIxADDR ")\n", to, from);
+	set_ac();
 	memcpy(VirtFromPhys(to), VirtFromPhys(from), B_PAGE_SIZE);
+	clear_ac();
 }
diff --git a/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.h b/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.h
index 19837441ac..2d9e8a148c 100644
--- a/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.h
+++ b/src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.h
@@ -48,6 +48,9 @@ struct RISCV64VMTranslationMap: public VMTranslationMap {
 			status_t			ProtectArea(VMArea* area,
 									uint32 attributes);
 
+			status_t			SetFlags(addr_t virtualAddress,
+									uint32 flags);
+
 	virtual	status_t			ClearFlags(addr_t virtualAddress,
 									uint32 flags);
 
diff --git a/src/system/kernel/arch/riscv64/arch_vm.cpp b/src/system/kernel/arch/riscv64/arch_vm.cpp
index 0027e0ed7f..d70fb21f00 100644
--- a/src/system/kernel/arch/riscv64/arch_vm.cpp
+++ b/src/system/kernel/arch/riscv64/arch_vm.cpp
@@ -10,8 +10,10 @@
 #include <arch/vm.h>
 #include <boot/kernel_args.h>
 
+#include "RISCV64VMTranslationMap.h"
 
-//#define TRACE_ARCH_VM
+
+#define TRACE_ARCH_VM
 #ifdef TRACE_ARCH_VM
 #	define TRACE(x) dprintf x
 #else
@@ -19,6 +21,182 @@
 #endif
 
 
+static uint64_t
+SignExtendVirtAdr(uint64_t virtAdr)
+{
+	if (((uint64_t)1 << 38) & virtAdr)
+		return virtAdr | 0xFFFFFF8000000000;
+	return virtAdr;
+}
+
+
+static Pte*
+LookupPte(phys_addr_t pageTable, addr_t virtAdr)
+{
+	Pte *pte = (Pte*)VirtFromPhys(pageTable);
+	for (int level = 2; level > 0; level --) {
+		pte += VirtAdrPte(virtAdr, level);
+		if (!((1 << pteValid) & pte->flags)) {
+			return NULL;
+		}
+		pte = (Pte*)VirtFromPhys(B_PAGE_SIZE * pte->ppn);
+	}
+	pte += VirtAdrPte(virtAdr, 0);
+	return pte;
+}
+
+
+
+static void
+WritePteFlags(uint32 flags)
+{
+	bool first = true;
+	dprintf("{");
+	for (uint32 i = 0; i < 32; i++) {
+		if ((1 << i) & flags) {
+			if (first) first = false; else dprintf(", ");
+			switch (i) {
+			case pteValid:    dprintf("valid"); break;
+			case pteRead:     dprintf("read"); break;
+			case pteWrite:    dprintf("write"); break;
+			case pteExec:     dprintf("exec"); break;
+			case pteUser:     dprintf("user"); break;
+			case pteGlobal:   dprintf("global"); break;
+			case pteAccessed: dprintf("accessed"); break;
+			case pteDirty:    dprintf("dirty"); break;
+			default:          dprintf("%" B_PRIu32, i);
+			}
+		}
+	}
+	dprintf("}");
+}
+
+
+static void
+DumpPageWrite(uint64_t virtAdr, uint64_t physAdr, size_t size, uint64 flags, uint64& firstVirt, uint64& firstPhys, uint64& firstFlags, uint64& len)
+{
+	if (virtAdr == firstVirt + len && physAdr == firstPhys + len && flags == firstFlags) {
+		len += size;
+	} else {
+		if (len != 0) {
+			dprintf("  0x%08" B_PRIxADDR " - 0x%08" B_PRIxADDR,
+				firstVirt, firstVirt + (len - 1));
+			dprintf(": 0x%08" B_PRIxADDR " - 0x%08" B_PRIxADDR ", %#" B_PRIxADDR ", ", firstPhys, firstPhys + (len - 1), len);
+			WritePteFlags(firstFlags); dprintf("\n");
+		}
+		firstVirt = virtAdr;
+		firstPhys = physAdr;
+		firstFlags = flags;
+		len = size;
+	}
+}
+
+
+static void
+DumpPageTableInt(Pte* pte, uint64_t virtAdr, uint32_t level, uint64& firstVirt, uint64& firstPhys, uint64& firstFlags, uint64& len)
+{
+	for (uint32 i = 0; i < pteCount; i++) {
+		if (((1 << pteValid) & pte[i].flags) != 0) {
+			if ((((1 << pteRead) | (1 << pteWrite) | (1 << pteExec)) & pte[i].flags) == 0) {
+				if (level == 0)
+					kprintf("  internal page table on level 0\n");
+
+				DumpPageTableInt((Pte*)VirtFromPhys(pageSize*pte[i].ppn),
+					virtAdr + ((uint64_t)i << (pageBits + pteIdxBits*level)),
+					level - 1, firstVirt, firstPhys, firstFlags, len);
+			} else {
+				DumpPageWrite(
+					SignExtendVirtAdr(virtAdr + ((uint64_t)i << (pageBits + pteIdxBits*level))),
+					pte[i].ppn * B_PAGE_SIZE,
+					1 << (pageBits + pteIdxBits*level),
+					pte[i].flags,
+					firstVirt, firstPhys, firstFlags, len);
+			}
+		}
+	}
+}
+
+
+static int
+DumpPageTable(int argc, char** argv)
+{
+	SatpReg satp;
+	if (argc >= 2) {
+		team_id id = strtoul(argv[1], NULL, 0);
+		VMAddressSpace* addrSpace = VMAddressSpace::DebugGet(id);
+		if (addrSpace == NULL) {
+			kprintf("could not find team %" B_PRId32 "\n", id);
+			return 0;
+		}
+		satp.val = ((RISCV64VMTranslationMap*)
+			addrSpace->TranslationMap())->Satp();
+		dprintf("page table for team %" B_PRId32 "\n", id);
+	} else {
+		satp.val = Satp();
+		dprintf("current page table:\n");
+	}
+	Pte* root = (Pte*)VirtFromPhys(satp.ppn * B_PAGE_SIZE);
+
+	uint64 firstVirt = 0;
+	uint64 firstPhys = 0;
+	uint64 firstFlags = 0;
+	uint64 len = 0;
+	DumpPageTableInt(root, 0, 2, firstVirt, firstPhys, firstFlags, len);
+	DumpPageWrite(0, 0, 0, 0, firstVirt, firstPhys, firstFlags, len);
+
+	return 0;
+}
+
+
+static int
+DumpVirtPage(int argc, char** argv)
+{
+	int curArg = 1;
+	SatpReg satp;
+
+	satp.val = Satp();
+	while (argv[curArg][0] == '-') {
+		if (strcmp(argv[curArg], "-team") == 0) {
+			curArg++;
+			team_id id = strtoul(argv[curArg++], NULL, 0);
+			VMAddressSpace* addrSpace = VMAddressSpace::DebugGet(id);
+			if (addrSpace == NULL) {
+				kprintf("could not find team %" B_PRId32 "\n", id);
+				return 0;
+			}
+			satp.val = ((RISCV64VMTranslationMap*)
+				addrSpace->TranslationMap())->Satp();
+		} else {
+			kprintf("unknown flag \"%s\"\n", argv[curArg]);
+			return 0;
+		}
+	}
+
+	kprintf("satp: %#" B_PRIx64 "\n", satp.val);
+
+	uint64 firstVirt = 0;
+	uint64 firstPhys = 0;
+	uint64 firstFlags = 0;
+	uint64 len = B_PAGE_SIZE;
+	if (!evaluate_debug_expression(argv[curArg++], &firstVirt, false))
+		return 0;
+
+	firstVirt = ROUNDDOWN(firstVirt, B_PAGE_SIZE);
+
+	Pte* pte = LookupPte(satp.ppn * B_PAGE_SIZE, firstVirt);
+	if (pte == NULL) {
+		dprintf("not mapped\n");
+		return 0;
+	}
+	firstPhys = pte->ppn * B_PAGE_SIZE;
+	firstFlags = pte->flags;
+
+	DumpPageWrite(0, 0, 0, 0, firstVirt, firstPhys, firstFlags, len);
+
+	return 0;
+}
+
+
 status_t
 arch_vm_init(kernel_args *args)
 {
@@ -29,13 +207,16 @@ arch_vm_init(kernel_args *args)
 status_t
 arch_vm_init_post_area(kernel_args *args)
 {
-	void* address = (void*)KERNEL_PMAP_BASE;
+	void* address = (void*)args->arch_args.physMap.start;
 	area_id area = vm_create_null_area(VMAddressSpace::KernelID(),
 		"physical map area", &address, B_EXACT_ADDRESS,
-		KERNEL_PMAP_SIZE, 0);
+		args->arch_args.physMap.size, 0);
 	if (area < B_OK)
 		return area;
 
+	add_debugger_command("dump_page_table", &DumpPageTable, "Dump page table");
+	add_debugger_command("dump_virt_page", &DumpVirtPage, "Dump virtual page mapping");
+
 	return B_OK;
 }
 
@@ -50,15 +231,15 @@ arch_vm_init_post_modules(kernel_args *args)
 status_t
 arch_vm_init_end(kernel_args *args)
 {
-	TRACE(("arch_vm_init_end(): %lu virtual ranges to keep:\n",
+	TRACE(("arch_vm_init_end(): %" B_PRIu32 " virtual ranges to keep:\n",
 		args->arch_args.num_virtual_ranges_to_keep));
 
 	for (int i = 0; i < (int)args->arch_args.num_virtual_ranges_to_keep; i++) {
 		addr_range &range = args->arch_args.virtual_ranges_to_keep[i];
 
-		TRACE(("  start: %p, size: 0x%lx\n", (void*)range.start, range.size));
+		TRACE(("  start: %p, size: %#" B_PRIxSIZE "\n", (void*)range.start, range.size));
 
-#if 0
+#if 1
 		// skip ranges outside the kernel address space
 		if (!IS_KERNEL_ADDRESS(range.start)) {
 			TRACE(("    no kernel address, skipping...\n"));
@@ -104,6 +285,9 @@ arch_vm_aspace_swap(struct VMAddressSpace *from, struct VMAddressSpace *to)
 	// page directories include all kernel mappings as well. Furthermore our
 	// arch specific translation map data objects are ref-counted, so they won't
 	// go away as long as they are still used on any CPU.
+
+	SetSatp(((RISCV64VMTranslationMap*)to->TranslationMap())->Satp());
+	FlushTlbAll();
 }
 
 
diff --git a/src/system/kernel/arch/riscv64/arch_vm_translation_map.cpp b/src/system/kernel/arch/riscv64/arch_vm_translation_map.cpp
index 12df63ea9b..1f131ab669 100644
--- a/src/system/kernel/arch/riscv64/arch_vm_translation_map.cpp
+++ b/src/system/kernel/arch/riscv64/arch_vm_translation_map.cpp
@@ -32,51 +32,19 @@
 #endif
 
 
-// TODO: read from FDT
-HtifRegs  *volatile gHtifRegs  = (HtifRegs  *volatile)0x40008000;
-PlicRegs  *volatile gPlicRegs  = (PlicRegs  *volatile)0x40100000;
-ClintRegs *volatile gClintRegs = (ClintRegs *volatile)0x02000000;
-
+ssize_t gVirtFromPhysOffset = 0;
 
 phys_addr_t sPageTable = 0;
-bool sPagingEnabled = false;
 char sPhysicalPageMapperData[sizeof(RISCV64VMPhysicalPageMapper)];
 
 
-static inline
-void *VirtFromPhys(uint64_t physAdr)
-{
-	if (!sPagingEnabled)
-		return (void*)physAdr;
-	return (void*)(physAdr + (KERNEL_PMAP_BASE - 0x80000000));
-}
-
-
-static inline
-uint64_t PhysFromVirt(void *virtAdr)
-{
-	if (!sPagingEnabled)
-		return (uint64)virtAdr;
-	return (uint64)virtAdr - (KERNEL_PMAP_BASE - 0x80000000);
-}
-
-
-static uint64_t
-SignExtendVirtAdr(uint64_t virtAdr)
-{
-	if (((uint64_t)1 << 38) & virtAdr)
-		return virtAdr | 0xFFFFFF8000000000;
-	return virtAdr;
-}
-
-
 static Pte*
 LookupPte(addr_t virtAdr, bool alloc, kernel_args* args,
 	phys_addr_t (*get_free_page)(kernel_args *))
 {
 	Pte *pte = (Pte*)VirtFromPhys(sPageTable);
 	for (int level = 2; level > 0; level --) {
-		pte += PhysAdrPte(virtAdr, level);
+		pte += VirtAdrPte(virtAdr, level);
 		if (!((1 << pteValid) & pte->flags)) {
 			if (!alloc)
 				return NULL;
@@ -88,7 +56,7 @@ LookupPte(addr_t virtAdr, bool alloc, kernel_args* args,
 		}
 		pte = (Pte*)VirtFromPhys(B_PAGE_SIZE * pte->ppn);
 	}
-	pte += PhysAdrPte(virtAdr, 0);
+	pte += VirtAdrPte(virtAdr, 0);
 	return pte;
 }
 
@@ -102,101 +70,9 @@ Map(addr_t virtAdr, phys_addr_t physAdr, uint64 flags, kernel_args* args,
 	if (pte == NULL) panic("can't allocate page table");
 
 	pte->ppn = physAdr / B_PAGE_SIZE;
-	pte->flags = (1 << pteValid) | flags;
+	pte->flags = (1 << pteValid) | (1 << pteAccessed) | (1 << pteDirty) | flags;
 
-	if (sPagingEnabled) FlushTlbPage(virtAdr);
-}
-
-
-static void
-MapRange(addr_t virtAdr, phys_addr_t physAdr, size_t size, uint64 flags,
-	kernel_args* args, phys_addr_t (*get_free_page)(kernel_args *))
-{
-	dprintf("MapRange(0x%" B_PRIxADDR ", 0x%" B_PRIxADDR ", 0x%"
-		B_PRIxADDR ")\n", virtAdr, physAdr, size);
-	for (size_t i = 0; i < size; i += B_PAGE_SIZE)
-		Map(virtAdr + i, physAdr + i, flags, args, get_free_page);
-}
-
-
-static void
-PreallocKernelRange(kernel_args *args)
-{
-	Pte *root = (Pte*)VirtFromPhys(sPageTable);
-	// NOTE: adjust range if changing kernel address space range
-	for (int i = 0; i < 256; i++) {
-		Pte *pte = &root[i];
-		pte->ppn = vm_allocate_early_physical_page(args);
-		if (pte->ppn == 0) panic("can't alloc early physical page");
-		memset(VirtFromPhys(B_PAGE_SIZE * pte->ppn), 0, B_PAGE_SIZE);
-		pte->flags |= (1 << pteValid);
-	}
-}
-
-
-void
-EnablePaging()
-{
-	SatpReg satp;
-	satp.ppn = sPageTable / B_PAGE_SIZE;
-	satp.asid = 0;
-	satp.mode = satpModeSv39;
-	SetSatp(satp.val);
-	FlushTlbAll();
-	sPagingEnabled = true;
-}
-
-
-static void
-WritePteFlags(uint32 flags)
-{
-	bool first = true;
-	dprintf("{");
-	for (uint32 i = 0; i < 32; i++) {
-		if ((1 << i) & flags) {
-			if (first) first = false; else dprintf(", ");
-			switch (i) {
-			case pteValid:    dprintf("valid"); break;
-			case pteRead:     dprintf("read"); break;
-			case pteWrite:    dprintf("write"); break;
-			case pteExec:     dprintf("exec"); break;
-			case pteUser:     dprintf("user"); break;
-			case pteGlobal:   dprintf("global"); break;
-			case pteAccessed: dprintf("accessed"); break;
-			case pteDirty:    dprintf("dirty"); break;
-			default:          dprintf("%" B_PRIu32, i);
-			}
-		}
-	}
-	dprintf("}");
-}
-
-
-static void
-DumpPageTableInt(Pte* pte, uint64_t virtAdr, uint32_t level)
-{
-	for (uint32 i = 0; i < pteCount; i++) {
-		if ((1 << pteValid) & pte[i].flags) {
-			if (level == 0) {
-				dprintf("  0x%08" B_PRIxADDR,
-					SignExtendVirtAdr(virtAdr + i * B_PAGE_SIZE));
-				dprintf(": 0x%08" B_PRIxADDR ", ", pte[i].ppn * B_PAGE_SIZE);
-				WritePteFlags(pte[i].flags); dprintf("\n");
-			} else {
-				DumpPageTableInt((Pte*)VirtFromPhys(pageSize*pte[i].ppn),
-					virtAdr + ((uint64_t)i << (pageBits + pteIdxBits*level)),
-					level - 1);
-			}
-		}
-	}
-}
-
-
-static void
-DumpPageTable(Pte* root)
-{
-	dprintf("PageTable:\n");
-	DumpPageTableInt(root, 0, 2);
+	FlushTlbPage(virtAdr);
 }
 
 
@@ -208,49 +84,6 @@ arch_vm_translation_map_init(kernel_args *args,
 {
 	TRACE("vm_translation_map_init: entry\n");
 
-	sPageTable = vm_allocate_early_physical_page(args) * B_PAGE_SIZE;
-	PreallocKernelRange(args);
-
-	// TODO: don't hardcode RAM base
-	MapRange(KERNEL_PMAP_BASE, 0x80000000, args->physical_memory_range[0].size,
-		(1 << pteRead) | (1 << pteWrite),
-		args, vm_allocate_early_physical_page);
-
-	for (uint32 i = 0; i < args->num_virtual_allocated_ranges; i++) {
-		addr_t start = args->virtual_allocated_range[i].start;
-		size_t size = args->virtual_allocated_range[i].size;
-		MapRange(start, start, size,
-			(1 << pteRead) | (1 << pteWrite) | (1 << pteExec),
-			args, vm_allocate_early_physical_page);
-	}
-
-	// TODO: read from FDT
-	// CLINT
-	MapRange( 0x2000000,  0x2000000,  0xC0000, (1 << pteRead) | (1 << pteWrite),
-		args, vm_allocate_early_physical_page);
-	// HTIF
-	MapRange(0x40008000, 0x40008000,   0x1000, (1 << pteRead) | (1 << pteWrite),
-		args, vm_allocate_early_physical_page);
-	// PLIC
-	MapRange(0x40100000, 0x40100000, 0x400000, (1 << pteRead) | (1 << pteWrite),
-		args, vm_allocate_early_physical_page);
-
-	{
-		SstatusReg status(Sstatus());
-		status.sum = 1;
-		SetSstatus(status.val);
-	}
-
-	EnablePaging();
-
-	*_physicalPageMapper = new(&sPhysicalPageMapperData)
-		RISCV64VMPhysicalPageMapper();
-
-	if (false) {
-		DumpPageTable((Pte*)VirtFromPhys(sPageTable));
-		HtifShutdown();
-	}
-
 #ifdef TRACE_VM_TMAP
 	TRACE("physical memory ranges:\n");
 	for (uint32 i = 0; i < args->num_physical_memory_ranges; i++) {
@@ -272,7 +105,28 @@ arch_vm_translation_map_init(kernel_args *args,
 		addr_t end = start + args->virtual_allocated_range[i].size;
 		TRACE("  %" B_PRIxADDR " - %" B_PRIxADDR "\n", start, end);
 	}
+
+	TRACE("kernel args ranges:\n");
+	for (uint32 i = 0; i < args->num_kernel_args_ranges; i++) {
+		phys_addr_t start = args->kernel_args_range[i].start;
+		phys_addr_t end = start + args->kernel_args_range[i].size;
+		TRACE("  %" B_PRIxPHYSADDR " - %" B_PRIxPHYSADDR "\n", start, end);
+	}
 #endif
+	
+	{
+		SatpReg satp(Satp());
+		sPageTable = satp.ppn * B_PAGE_SIZE;
+	}
+	
+	dprintf("physMapBase: %#" B_PRIxADDR "\n", args->arch_args.physMap.start);
+	dprintf("physMemBase: %#" B_PRIxADDR "\n", args->physical_memory_range[0].start);
+	gVirtFromPhysOffset = args->arch_args.physMap.start - args->physical_memory_range[0].start;
+
+	clear_ac();
+
+	*_physicalPageMapper = new(&sPhysicalPageMapperData)
+		RISCV64VMPhysicalPageMapper();
 
 	return B_OK;
 }
@@ -294,14 +148,19 @@ arch_vm_translation_map_init_post_area(kernel_args *args)
 
 
 status_t
-arch_vm_translation_map_early_map(kernel_args *args, addr_t va, phys_addr_t pa,
-	uint8 attributes, phys_addr_t (*get_free_page)(kernel_args *))
+arch_vm_translation_map_early_map(kernel_args *args,
+	addr_t virtAdr, phys_addr_t physAdr, uint8 attributes,
+	phys_addr_t (*get_free_page)(kernel_args *))
 {
+	//dprintf("early_map(%#" B_PRIxADDR ", %#" B_PRIxADDR ")\n", virtAdr, physAdr);
 	uint64 flags = 0;
-	if ((attributes & B_KERNEL_READ_AREA)    != 0) flags |= (1 << pteRead);
-	if ((attributes & B_KERNEL_WRITE_AREA)   != 0) flags |= (1 << pteWrite);
-	if ((attributes & B_KERNEL_EXECUTE_AREA) != 0) flags |= (1 << pteExec);
-	Map(va, pa, flags, args, get_free_page);
+	if ((attributes & B_KERNEL_READ_AREA) != 0)
+		flags |= (1 << pteRead);
+	if ((attributes & B_KERNEL_WRITE_AREA) != 0)
+		flags |= (1 << pteWrite);
+	if ((attributes & B_KERNEL_EXECUTE_AREA) != 0)
+		flags |= (1 << pteExec);
+	Map(virtAdr, physAdr, flags, args, get_free_page);
 	return B_OK;
 }
 
-- 
2.30.2

